{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7605a287-69a2-4692-bdad-da8cfe807a01",
   "metadata": {
    "id": "7605a287-69a2-4692-bdad-da8cfe807a01"
   },
   "source": [
    "# Redes Convolucionales con Pytorch\n",
    "\n",
    "_Clasificación de imágenes_\n",
    "\n",
    "<b>Objetivos:</b>\n",
    "1. Clasifición de números con MNIST\n",
    "2. Comparar una red fully connected con una Convolucional\n",
    "3. Utilizar ResNet18 desde cero\n",
    "4. Utilizar ResNet18 con Transfer Learning\n",
    "\n",
    "<b>Paquetes a instalar:</b>\n",
    "Pytorch, Torchvision, cudnn, cudatoolkit, matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b04ecd-3d53-4e46-8469-f773cdb28476",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04b04ecd-3d53-4e46-8469-f773cdb28476",
    "outputId": "92b7049c-62b2-4ead-b16b-bc46bc3558eb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inicialización\n",
    "import torch\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c82c37-01dd-4ca2-95c4-68ad954216b7",
   "metadata": {
    "id": "89c82c37-01dd-4ca2-95c4-68ad954216b7"
   },
   "source": [
    "## Dataset de MNIST\n",
    "- Imágenes de 28x28 píxeles\n",
    "- 60.000 imágenes de training\n",
    "- 10.000 imágenes de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b0cd2-8050-4111-b75e-fc8056a7e4b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "b51b0cd2-8050-4111-b75e-fc8056a7e4b4",
    "outputId": "54628a86-e790-4459-819a-71ec23a62356",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definición de constantes \n",
    "import os\n",
    "\n",
    "# esto es para que funcione matplotlib \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 30\n",
    "IMAGE_SIZE = 28\n",
    "DATASET_DIR = 'data'\n",
    "MODELS_DIR = 'models/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf2b91f-db3a-48c7-9e6b-a17ff7222063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargamos dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importamos los conjuntos de training y test\n",
    "training = datasets.MNIST(DATASET_DIR, train=True, download=True,\n",
    "                          transform=ToTensor())\n",
    "testing = datasets.MNIST(DATASET_DIR, train=False, download=True,\n",
    "                      transform=ToTensor())\n",
    "\n",
    "# creamos los Dataloader para cada conjunto\n",
    "train_dataloader = DataLoader(training, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(testing, batch_size=BATCH_SIZE)\n",
    "\n",
    "# estructura de los batches\n",
    "X, y = next(iter(train_dataloader))\n",
    "print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "\n",
    "classes = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "num_classes = len(testing.class_to_idx)\n",
    "print('Classes:', testing.class_to_idx)\n",
    "print('Num classes:', num_classes)\n",
    "\n",
    "# mostramos las 9 primeras imágenes\n",
    "i=1\n",
    "for img,j in zip(X[:9],y[:9]):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.imshow(img.reshape((IMAGE_SIZE,IMAGE_SIZE)))\n",
    "    plt.title(j.item())\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca720adf-7872-48a4-b8c5-eafeaad60bda",
   "metadata": {
    "id": "ca720adf-7872-48a4-b8c5-eafeaad60bda"
   },
   "source": [
    "## Entrenamiento con fully connected network\n",
    "- Creación de una red con 2 capas ocultas\n",
    "- Estructura: entrada 784, oculta1 512, oculta2 512, salida 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e527b6-ec7e-42ff-afec-574fe7993aac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9e527b6-ec7e-42ff-afec-574fe7993aac",
    "outputId": "a5fe58b9-4f7b-4791-8dde-f6979c8a01b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definimos el modelo\n",
    "from torch import nn\n",
    "from torchinfo  import summary\n",
    "\n",
    "# creamos la red feed-forward\n",
    "class FullyConnected(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyConnected,self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(IMAGE_SIZE*IMAGE_SIZE, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = FullyConnected().to(device)\n",
    "\n",
    "summary(model,\n",
    "        input_size=(BATCH_SIZE, 1, IMAGE_SIZE, IMAGE_SIZE),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyYTATL08AKo",
   "metadata": {
    "id": "hyYTATL08AKo"
   },
   "source": [
    "### Procedimientos de training y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef97894-12e6-4e65-abe0-f23fedef43d2",
   "metadata": {
    "id": "8ef97894-12e6-4e65-abe0-f23fedef43d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# definimos la métrica y el optimizador\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# función de entrenamiento\n",
    "def train(dataloader, model, loss_fn, optimizer, losses, accuracy):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            current = (batch + 1) * len(X)\n",
    "            train_acc = 100*correct / size\n",
    "            losses.append(loss.item())\n",
    "            print(f\"Accuracy: {train_acc:>0.1f}%, Avg loss: {loss.item():>8f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    train_acc = 100*correct/size\n",
    "    accuracy.append(train_acc)\n",
    "\n",
    "\n",
    "# función de test\n",
    "def test(dataloader, model, loss_fn, losses, accuracy):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    test_acc = 100*correct/size\n",
    "    losses.append(test_loss)\n",
    "    accuracy.append(test_acc)\n",
    "    print(f\"Test Error: \\n Accuracy: {test_acc:>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PunFWQVFROUP",
   "metadata": {
    "id": "PunFWQVFROUP"
   },
   "source": [
    "### Bucle principal para Fully Connected Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TkoXNGsTRCio",
   "metadata": {
    "id": "TkoXNGsTRCio",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bucle de entranamiento\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, train_loss, train_acc)\n",
    "    test(test_dataloader, model, loss_fn, test_loss, test_acc)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model.state_dict(), MODELS_DIR+\"model_ff.pth\")\n",
    "print(\"Model saved model_ff.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XTcIwhPK8OEE",
   "metadata": {
    "id": "XTcIwhPK8OEE"
   },
   "source": [
    "### Gráficas de precisión y pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05430a-8f95-4ba2-8f65-45a45fca8003",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "8a05430a-8f95-4ba2-8f65-45a45fca8003",
    "outputId": "2917aec7-bb7b-4277-e8bb-c25d1c1d1c8d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_graphics(train_loss, train_acc, test_acc):\n",
    "\n",
    "    # Dibujamos las gráficas\n",
    "    x = range(len(train_loss))\n",
    "    plt.figure()\n",
    "    plt.plot(x,train_loss, color='blue')\n",
    "    plt.legend(['Train Loss'], loc='upper right')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('train_loss.svg')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(train_acc, color='blue')\n",
    "    plt.plot(test_acc, color='red')\n",
    "    plt.legend(['Train Accuracy', 'Test Accuracy'], loc='lower right')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig('Accuracy.svg')\n",
    "    \n",
    "draw_graphics(train_loss, train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_t1FJ9lV-EKB",
   "metadata": {
    "id": "_t1FJ9lV-EKB"
   },
   "source": [
    "### Visualización de dígitos mal clasificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GTQm7Mq7-MuQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GTQm7Mq7-MuQ",
    "outputId": "8476ba4b-df13-493b-acea-76c7a97f84c2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Función para buscar incorrectos y dibujarlos\n",
    "def draw_incorrect(model, dataloader, num=3):\n",
    "    for i in range(num):\n",
    "        X, y = next(iter(dataloader))\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        model.to(device)\n",
    "        pred = model(X)\n",
    "        incorrect = (pred.argmax(1) != y)\n",
    "        for img,l,d in zip(X[incorrect],y[incorrect],pred[incorrect].argmax(1)):\n",
    "            img, l = img.to('cpu'), l.to('cpu')\n",
    "            plt.imshow(img.reshape((IMAGE_SIZE,IMAGE_SIZE)))\n",
    "            plt.title(f\"{l.item()} - {d.item()}\")\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "        \n",
    "# Contamos el número de elementos que hay de cada dígito\n",
    "count = np.zeros(10, np.int32)\n",
    "for _,y in test_dataloader:\n",
    "    np.add.at(count, y, 1)\n",
    "\n",
    "print(\"Numero elementos por digito:\", count)\n",
    "print(\"Total:\", count.sum())\n",
    "\n",
    "draw_incorrect(model, test_dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba8358-2845-4494-8701-c264ac794c8e",
   "metadata": {
    "id": "adba8358-2845-4494-8701-c264ac794c8e"
   },
   "source": [
    "## Entrenamiento con redes convolucionales simples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a40d903-85c7-40dc-bd4d-22f2c92260b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ConvNet1\n",
    "- 2 Bloques Convolucionales\n",
    "- 1 Fully-connected\n",
    "\n",
    "### ConvNet2\n",
    "- 2 Bloques Convolucionales\n",
    "- 1 Fully-connected\n",
    "- BatchNormalization\n",
    "\n",
    "### ConvNet3\n",
    "- 3 Bloques Convolucionales\n",
    "- 1 Fully-connected\n",
    "- BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d9f15-c71d-4c55-98fe-718fd7bf9eb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "529d9f15-c71d-4c55-98fe-718fd7bf9eb4",
    "outputId": "bf7b31fc-84d8-4caa-9d02-7ea8c97997d0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definimos las redes convolucionales\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "def bloque_conv(in_features, out_features):\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(in_features, out_features, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "def bloque_conv_norm(in_features, out_features):\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(in_features, out_features, 3, 1),\n",
    "            nn.BatchNorm2d(out_features),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "class ConvNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet1, self).__init__()\n",
    "        self.conv1 = bloque_conv(1, 32)\n",
    "        self.conv2 = bloque_conv(32, 64)\n",
    "        self.linear_out = nn.Sequential(\n",
    "            #nn.Dropout(0.25),\n",
    "            nn.Flatten(),\n",
    "            #nn.Linear(1600, 128),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(1600, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        logits = self.linear_out(x)\n",
    "        return logits\n",
    "\n",
    "    \n",
    "class ConvNet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet2, self).__init__()\n",
    "        self.conv1 = bloque_conv_norm(1, 32)\n",
    "        self.conv2 = bloque_conv_norm(32, 64)\n",
    "        self.linear_out = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1600, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        logits = self.linear_out(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class ConvNet3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet3, self).__init__()\n",
    "        self.conv1 = bloque_conv_norm(1, 32)\n",
    "        self.conv2 = bloque_conv_norm(32, 64)\n",
    "        self.conv3 = bloque_conv_norm(64, 128)\n",
    "        self.linear_out = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        logits = self.linear_out(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793a5db-df59-4846-b7bc-30f7f529e227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creamos el modelo\n",
    "model = ConvNet3() #ConvNet1 #ConvNet2\n",
    "model.to(device)\n",
    "\n",
    "summary(model,\n",
    "        input_size=(BATCH_SIZE, 1, IMAGE_SIZE, IMAGE_SIZE),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0c1ce-d7e4-4869-bfb4-77bd40a46a48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ff0c1ce-d7e4-4869-bfb4-77bd40a46a48",
    "outputId": "1c4ebc48-6d53-4ce2-96b0-f7c220cc6b50",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "# bucle principal\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}/{EPOCHS}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, train_loss, train_acc)\n",
    "    test(test_dataloader, model, loss_fn, test_loss, test_acc)\n",
    "\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model.state_dict(), MODELS_DIR+\"model_cnn1.pth\")\n",
    "print(\"Model saved model_cnn1.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0061c-a367-4758-beeb-04628e897833",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 933
    },
    "id": "eff0061c-a367-4758-beeb-04628e897833",
    "outputId": "453fde04-853f-4203-a67d-1e165b268aa4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_loss[-1])\n",
    "print(train_acc[-1])\n",
    "print(test_acc[-1])\n",
    "\n",
    "draw_graphics(train_loss, train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac2bba-db9f-4961-b294-4b57715c4cad",
   "metadata": {
    "id": "48ac2bba-db9f-4961-b294-4b57715c4cad",
    "tags": []
   },
   "source": [
    "## Entrenamiento con ResNet18 desde Cero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad488cc-6808-446c-8450-4cf6a1ffbe32",
   "metadata": {
    "id": "9ad488cc-6808-446c-8450-4cf6a1ffbe32",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import Grayscale, ToTensor\n",
    "\n",
    "model = resnet18()\n",
    "\n",
    "transform = Compose([\n",
    "    Grayscale(num_output_channels=3),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "training = datasets.MNIST('data', train=True, download=True,\n",
    "                          transform=transform )\n",
    "testing = datasets.MNIST('data', train=False, download=True,\n",
    "                      transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(training, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(testing, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "# Cambiamos la capa superior con una capa Lineal con el número de clases\n",
    "num_features = model.fc.in_features\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.5, inplace=True),\n",
    "    torch.nn.Linear(in_features=num_features,\n",
    "                    out_features=num_classes,\n",
    "                    bias=True)).to(device)\n",
    "\n",
    "summary(model,\n",
    "        input_size=(BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0148bf1-b282-4aab-a83f-df345ba02e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "epochs = EPOCHS\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}/{epochs}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, train_loss, train_acc)\n",
    "    test(test_dataloader, model, loss_fn, test_loss, test_acc)\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model.state_dict(), MODELS_DIR+\"model_resnet.pth\")\n",
    "print(\"Model saved to model_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b303291d-6294-4e5a-a31b-f39ae6431ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_loss[-1])\n",
    "print(train_acc[-1])\n",
    "print(test_acc[-1])\n",
    "\n",
    "draw_graphics(train_loss, train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e83a4-d612-44f6-9fa0-27b960161494",
   "metadata": {
    "id": "0c5e83a4-d612-44f6-9fa0-27b960161494",
    "tags": []
   },
   "source": [
    "## Entrenamiento con ResNet18 y Transfer Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6dc4e-9fca-4cf6-9219-c48e3ef24a29",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "id": "4bb6dc4e-9fca-4cf6-9219-c48e3ef24a29",
    "outputId": "7f67f460-9140-46d6-c8df-e3bee2dab9f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision.transforms import Compose, Grayscale\n",
    "import numpy as np\n",
    "\n",
    "# Instanciamos el modelo ResNet18 con los pesos por defecto\n",
    "weights=ResNet18_Weights.DEFAULT\n",
    "auto_transforms = weights.transforms()\n",
    "\n",
    "# Cargamos el dataset con las transformaciones originales\n",
    "transform=Compose([\n",
    "    Grayscale(num_output_channels=3),\n",
    "    auto_transforms,\n",
    "])\n",
    "\n",
    "training = datasets.MNIST('data', train=True, download=True,\n",
    "                          transform=transform)\n",
    "testing = datasets.MNIST('data', train=False, download=True,\n",
    "                      transform=transform)\n",
    "\n",
    "# Seleccionamos un subconjunto de imágenes de entrenamiento \n",
    "reduced_training = Subset(training, range(2500))\n",
    "\n",
    "train_dataloader = DataLoader(reduced_training, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(testing, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Estructura de los batches\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "# Creamos el modelo y congelamos parámetros de la red\n",
    "model = resnet18(weights=weights).to(device)\n",
    "for name, para in model.named_parameters():\n",
    "    para.requires_grad = False\n",
    "\n",
    "# Cambiamos la capa superior con una capa Lineal con 10 clases de salida\n",
    "num_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(in_features=num_features,\n",
    "                    out_features=num_classes,\n",
    "                    bias=True).to(device)\n",
    "\n",
    "summary(model,\n",
    "        input_size=(BATCH_SIZE, 3, IMAGE_SIZE, IMAGE_SIZE),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a6a67-de58-41c5-82d8-2c6494fddb50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "epochs = EPOCHS\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}/{epochs}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, train_loss, train_acc)\n",
    "    test(test_dataloader, model, loss_fn, test_loss, test_acc)\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model.state_dict(), MODELS_DIR+\"model_resnet_tl1.pth\")\n",
    "print(\"Model saved to model_resnet_tl1.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282ec01-81f0-4f16-bc9a-724867908b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_loss[-1])\n",
    "print(train_acc[-1])\n",
    "print(test_acc[-1])\n",
    "\n",
    "draw_graphics(train_loss, train_acc, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972227e-3e8e-4ee7-b20b-aaa7f1048bcc",
   "metadata": {
    "id": "6972227e-3e8e-4ee7-b20b-aaa7f1048bcc"
   },
   "source": [
    "### Mejoramos el resultado entrenando la red completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09765636-ce89-4414-90d9-c0e4c81862a3",
   "metadata": {
    "id": "09765636-ce89-4414-90d9-c0e4c81862a3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "for name, para in model.named_parameters():\n",
    "    para.requires_grad = True\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}/{epochs}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, train_loss, train_acc)\n",
    "    test(test_dataloader, model, loss_fn, test_loss, test_acc)\n",
    "print(\"Done!\")\n",
    "\n",
    "torch.save(model.state_dict(), MODELS_DIR+\"model_resnet_tl2.pth\")\n",
    "print(\"Model saved to model_resnet_tl2.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033a21a-ce33-4455-8ce7-d3f237c46e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_loss[-1])\n",
    "print(train_acc[-1])\n",
    "print(test_acc[-1])\n",
    "\n",
    "draw_graphics(train_loss, train_acc, test_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
